{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urbansim Buildings Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "Once AWS access is restored:\n",
    "\n",
    "- Re-run Update_urbansim_buildings_county.ipynb\n",
    "    - Select distinct -> drop duplicates in urbansim_buildings tables\n",
    "    \n",
    "### Verify:\n",
    "\n",
    "- joinid should be unique to APN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "user = os.environ['USER']\n",
    "sys.path.insert(0, '/Users/{}/Box/DataViz Projects/Utility Code'.format(user))\n",
    "from utils_io import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get data from Socrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# buildings_2018\n",
    "socrata_data_id = 'ahwz-jtst'\n",
    "df = pull_df_from_socrata(socrata_data_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspect duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lots of duplicates\n",
    "print(df.shape)  # (3655207, 15)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)  # (3120776, 15)\n",
    "# Duplicate APNs (makes sense since we're using buildings)\n",
    "print(df['apn'].nunique())  # 2643041"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Subset to data with values for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_cols = ['assessed_building_value', 'assessed_date', 'building_id',\n",
    "               'building_sqft', 'building_type', \n",
    "               'jurisdiction_cty', 'last_sale_date', 'non_residential_sqft',\n",
    "               'residential_units', 'tenure', 'year_built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to data with values\n",
    "df['missing_cty_input'] = df[county_cols].isnull().all(axis=1)\n",
    "cty_data = df[df['missing_cty_input'] == False].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there are duplicate records for buildings where the duplicate record has no building id.\n",
    "\n",
    "Solution: Drop null values using building_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cty_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop null building ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this doesn't work since value is 'nan' not NaN\n",
    "# cty_data.dropna(subset=['building_id'], inplace=True)\n",
    "\n",
    "# instead\n",
    "cty_data = cty_data[cty_data['building_id'] != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cty_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reassess duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cty_data.shape)  # (476300, 16)\n",
    "# still duplicate building ids\n",
    "print(cty_data['building_id'].nunique())  # 475110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target # of buildings\n",
    "target_num_buildings = cty_data[cty_data['fipco'] == 'CA085']['building_id'].nunique()\n",
    "target_num_buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the duplicate values are arising from the merge (on APN) of county data and Parcels 2018 data.\n",
    "\n",
    "Parcels 2018 appears to have APNs for Marin (fipco CA041) and San Francisco (fipco CA075) that match Santa Clara APNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcs = cty_data.groupby('building_id').size().sort_values(ascending=False)\n",
    "dup_data = cty_data[cty_data['building_id'].isin(vcs[vcs > 1].index)]\n",
    "dup_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it looks like duplicate values are arising from the same merge, but this time the problem is a many to one joinid:apn relationship.\n",
    "\n",
    "This is only the case for one APN: 13241104\n",
    "\n",
    "Solution: select one of the joinids as the correct one (verify with Parcels 2018 which one ought to be chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dup_data['fipco'].value_counts())\n",
    "sc_dups = dup_data[dup_data['fipco'] == 'CA085']\n",
    "\n",
    "vcs1 = sc_dups.groupby('building_id').size().sort_values(ascending=False)\n",
    "dup_sc = sc_dups[sc_dups['building_id'].isin(vcs1[vcs1 > 1].index)]\n",
    "print(dup_sc['apn'].unique())\n",
    "dup_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cleaned version of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_dup = cty_data[cty_data['building_id'].isin(vcs[vcs == 1].index)]\n",
    "sc_nondup = sc_dups[sc_dups['building_id'].isin(vcs1[vcs1 == 1].index)]\n",
    "\n",
    "buildings = pd.concat([non_dup, sc_nondup, dup_sc.iloc[[0]]])\n",
    "buildings = buildings[buildings['fipco'] == 'CA085']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings[buildings['fipco'] == 'CA085']\n",
    "# building id is now unique\n",
    "assert len(buildings) == target_num_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check match with Parcels 2018 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without match in Parcels 2018: AL, MI, LI, RE, CO, SM, MO, WA, HO\n",
    "\n",
    "d = {'SJ': 'San Jose',\n",
    "     'SC': 'Santa Clara',\n",
    "     'SU': 'Sunnyvale',\n",
    "     'PA': 'Palo Alto',\n",
    "     'MV': 'Mountain View',\n",
    "     'ST': None,\n",
    "     'LA': 'Los Altos',\n",
    "     'AL': None,\n",
    "     'LH': 'Los Altos Hills',\n",
    "     'PV': 'Portola Valley',\n",
    "     'MI': None,\n",
    "     'CA': 'Campbell',\n",
    "     'CU': 'Cupertino',\n",
    "     'LG': 'Los Gatos',\n",
    "     'SA': 'Saratoga',\n",
    "     'MS': 'Monte Sereno',\n",
    "     'LI': None,\n",
    "     'MH': 'Morgan Hill',\n",
    "     'RE': None,\n",
    "     'GI': 'Gilroy',\n",
    "     'CO': None,\n",
    "     'SM': None,\n",
    "     'MO': None,\n",
    "     'WA': None,\n",
    "     'HO': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_jurisdict = list(set(buildings['jurisdict'].unique()).difference(set(d.values())))\n",
    "missing_jurisdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in missing_jurisdict:\n",
    "    print(j, '\\n')\n",
    "    print(buildings[buildings['jurisdict'] == j]['jurisdiction_cty'].value_counts())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings['juris_compare'] = buildings['jurisdiction_cty'] + ' ' + buildings['jurisdict']\n",
    "buildings['juris_compare'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in d.items():\n",
    "    print('\\n', v)\n",
    "    print(buildings[buildings['jurisdiction_cty'] == k]['jurisdict'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.to_csv('urbanim_buildings_proc.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
